{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BqxFqVTNnWqQ"
   },
   "source": [
    "### Import Libraries\n",
    "OpenCV, NumPy and Matplotlib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bTYwbsF1ukO9"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import joblib\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ieLvs6yOnljy"
   },
   "source": [
    "### Define Constants\n",
    "A set of constants which we will be using throughout the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p1F-GX41vGd7"
   },
   "outputs": [],
   "source": [
    "''' Dimensions of the frame which will form our dataset '''\n",
    "frame_height = 240\n",
    "frame_width = 360\n",
    "\n",
    "''' The desired crop size which we use for constructing the windows of our dataset ''' \n",
    "window_dim = 80\n",
    "\n",
    "''' Definition of important directories '''\n",
    "dataset_directory = './'\n",
    "videos_directory = '../Clips/Train/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z8n20r8nnvDI"
   },
   "source": [
    "### Define window sequence analyzers\n",
    "Here, I define a set of functions which will provide us some information about any given triple of windows, which in turn will help us in deciding whether to include the given triple within our dataset or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5oTDcxEbzJKk"
   },
   "source": [
    "Usually, we would want only those triples whithin our dataset for which intermediate window generation is neither too easy, nor too difficult. The first function, `average_frame_evaluator` calculates a value which indicates how well the average window fares as the intermediate window. We can use the performance of the average window(as the intermediate window) as a measure of how difficult or easy intermediate window generation is for a given triple. For any given triple, if the function `average_frame_evaluator` calculates a relatively small value, it indicates that very little movement of objects takes place within the window. \n",
    "\n",
    "Whenever we use a continuous sequence of frames for generating a set of triples for our dataset, we are bound to run into triples across which a scene change or a scene break occcurs. These triples are pretty much useless, and we would not want to include them in our dataset. The third function, `detect_broken_frame_sequence` filters out any such triples from a given set of triples, by making use of the first two functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YLz02oDEIBIR"
   },
   "outputs": [],
   "source": [
    "def average_window_evaluator(example):\n",
    "    average_window = (example[0].astype(np.uint64) + example[2].astype(np.uint64)) // 2\n",
    "    average_window_accuracy_metric = np.mean((average_window - example[1]) ** 2)\n",
    "    return average_window_accuracy_metric\n",
    "\n",
    "def window_triple_break_evaluator(example):\n",
    "    window1_mid_diff = np.mean((example[0].astype(np.uint64) - example[1].astype(np.uint64)) ** 2)\n",
    "    window2_mid_diff = np.mean((example[2].astype(np.uint64) - example[1].astype(np.uint64)) ** 2)\n",
    "    return (window1_mid_diff - window2_mid_diff) / (window1_mid_diff + window2_mid_diff)\n",
    "\n",
    "def detect_broken_window_triple(example):\n",
    "    average_window_diff = average_window_evaluator(example)\n",
    "    window_triple_broken_prob = abs(window_triple_break_evaluator(example))\n",
    "    if window_triple_broken_prob >= 0.20 and average_window_diff > 5000:\n",
    "        return False\n",
    "    if window_triple_broken_prob >= 0.35 and average_window_diff > 3000:\n",
    "        return False\n",
    "    if window_triple_broken_prob >= 0.50 and average_window_diff > 2000:\n",
    "        return False\n",
    "    if window_triple_broken_prob >= 0.60 and average_window_diff > 1200:\n",
    "        return False\n",
    "    if window_triple_broken_prob >= 0.70 and average_window_diff > 600:\n",
    "        return False\n",
    "    if window_triple_broken_prob >= 0.80 and average_window_diff > 100:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5vE0sKABakiJ"
   },
   "source": [
    "### Define functions to detect noisy frames\n",
    "\n",
    "The two functions defined below help in deciding whether a frame contains a lot of noise, or a large number of small objects which could be hard to keep track of in any kind of motion. The two functions are completely similar in what they try to achieve. However, the first function is more precise but slower, and the second is less precise but faster.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pKeRFiyb3FRf"
   },
   "source": [
    "The first function detects noise(or a large collection of small objects) in a given frame by measuring how simliar the neighboring pixels of any given pixel are to itself, and then aggregating this measure for all pixels within the frame. \n",
    "The second function detects noise within a given frame by first downscaling the frame, and then upscaling it back to its original resolution, and comparing the resulting frame against the original frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KF__9gL8aihS"
   },
   "outputs": [],
   "source": [
    "def frame_speckiness_evaluator(frame, translation):\n",
    "    total_diff = 0\n",
    "    frame_width = frame.shape[0]\n",
    "    frame_height = frame.shape[1]\n",
    "    frame = frame.astype(np.int32)\n",
    "\n",
    "    for i in range(-translation, translation + 1):\n",
    "        for j in range(-translation, translation + 1):\n",
    "            window_1 = frame[max(0, i):min(frame_height, frame_height + i), \n",
    "                                max(0, j):min(frame_width, frame_width + j), 0:3]\n",
    "            window_2 = frame[max(0, -i):min(frame_height, frame_height - i), \n",
    "                                max(0, -j):min(frame_width, frame_width - j), 0:3]\n",
    "            diff = ((np.sum(abs(window_1 - window_2), axis=2) > 80).astype(np.uint32)) * 200\n",
    "            total_diff += (np.sum(diff) / (frame_width * frame_height * \n",
    "                                (translation ** 2)))\n",
    "    return total_diff\n",
    "\n",
    "def frame_bloom_evaluator(frame, factor):\n",
    "    total_diff = 0\n",
    "    frame_width = frame.shape[0]\n",
    "    frame_height = frame.shape[1]\n",
    "    window_1 = frame\n",
    "    window_2 = cv2.resize(cv2.resize(frame, (int(frame_width * factor), int(frame_height * factor))), (frame_width, frame_height))\n",
    "    diff = ((abs(window_1.astype(np.int32) - window_2.astype(np.int32)) > 5).astype(np.uint64)) * 20\n",
    "    total_diff += (np.sum(diff) / (frame_width * frame_height))\n",
    "    return total_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wHelQlBj6CtJ"
   },
   "source": [
    "### Define threshold values which will be used for filtering\n",
    "These values may change slightly, depending the window size used for cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G4ApovBx0Hnp"
   },
   "outputs": [],
   "source": [
    "WINDOW_TRIPLE_AVERAGE_DIFF_LOWER_THRESHOLD_VAL = 100\n",
    "WINDOW_TRIPLE_AVERAGE_DIFF_UPPER_THRESHOLD_VAL = 15000\n",
    "FRAME_SPECKINESS_THRESHOLD_VALUE = 420\n",
    "FRAME_SPECKINESS_TRANSLATION_FACTOR = 1\n",
    "FRAME_BLOOM_THRESHOLD_VALUE = 30\n",
    "FRAME_BLOOM_FACTOR = 0.27"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pd_VUrvtogP-"
   },
   "source": [
    "### Define function to extract useful window triples from a list of triples\n",
    "The following function filters out all unneccesary window triples from a given list of window triples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FKtPqkYoM6iR"
   },
   "outputs": [],
   "source": [
    "def extract_useful_window_triples(triple_list):\n",
    "    triple_list = filter(lambda x: (WINDOW_TRIPLE_AVERAGE_DIFF_UPPER_THRESHOLD_VAL > \n",
    "                        average_window_evaluator(x) > WINDOW_TRIPLE_AVERAGE_DIFF_LOWER_THRESHOLD_VAL), \n",
    "                        triple_list)\n",
    "    triple_list = filter(lambda x: detect_broken_window_triple(x), triple_list)\n",
    "    triple_list = filter(lambda x: (frame_speckiness_evaluator(x[0], FRAME_SPECKINESS_TRANSLATION_FACTOR) <= \n",
    "                        FRAME_SPECKINESS_THRESHOLD_VALUE and frame_speckiness_evaluator(x[1], \n",
    "                        FRAME_SPECKINESS_TRANSLATION_FACTOR) <= FRAME_SPECKINESS_THRESHOLD_VALUE), triple_list)\n",
    "    triple_list = list(triple_list)\n",
    "    print(\"Useful sequence count =\", len(triple_list))\n",
    "\n",
    "    return triple_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4_KR31zKon33"
   },
   "source": [
    "### Define function to get a set of candidate window triples from a series of continuos frames\n",
    "The following function retreives a set of candidate window triple from a series of continuos frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MFvp-z4KKuzn"
   },
   "outputs": [],
   "source": [
    "def get_window_triples(frame_list, max_sequence_count, crop_image_dist, gap_3_prob, gap_5_prob, gap_7_prob):\n",
    "    cropped_sequences = []\n",
    "    start = 0\n",
    "    while(len(cropped_sequences) < max_sequence_count and start + 10 < len(frame_list)):\n",
    "        gap_estimator = random.random()\n",
    "        if gap_estimator <= gap_3_prob:\n",
    "            gap = 3\n",
    "        elif gap_estimator <= gap_3_prob + gap_5_prob:\n",
    "            gap = 5\n",
    "        else:\n",
    "            gap = 7\n",
    "\n",
    "        Y = frame_list[start + gap // 2]\n",
    "        X2 = frame_list[start + gap - 1]\n",
    "        X1 = frame_list[start]\n",
    "        for i in range(0, frame_height - window_dim, crop_image_dist):\n",
    "            for j in range(0, frame_width - window_dim, crop_image_dist):\n",
    "                y, x = i, j\n",
    "                Y_cropped = Y[y:y + window_dim, x:x + window_dim, :].astype(np.uint8)\n",
    "                X2_cropped = X2[y:y + window_dim, x:x + window_dim, :].astype(np.uint8)\n",
    "                X1_cropped = X1[y:y + window_dim, x:x + window_dim, :].astype(np.uint8)\n",
    "                cropped_sequences.append((X1_cropped, Y_cropped, X2_cropped))\n",
    "\n",
    "        start = start + gap\n",
    "\n",
    "    print(\"Cropped sequence count =\", len(cropped_sequences))\n",
    "    return cropped_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HkUYAh9No3u8"
   },
   "source": [
    "### Define function to get continuous frames from a clip\n",
    "The following function retreives a given number of continuos frames from a video clip, given a starting frame index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5uouGO-bKAYw"
   },
   "outputs": [],
   "source": [
    "def get_frames(file_path, start_frame, num_frames):\n",
    "    frames = []\n",
    "    frame_count = 0\n",
    "    video = cv2.VideoCapture(file_path)\n",
    "    while (video.isOpened()):\n",
    "        ret, frame = video.read()\n",
    "        if ret == True:\n",
    "            frame_count += 1\n",
    "            if frame_count >= start_frame:\n",
    "                if len(frames) <= num_frames:\n",
    "                    frames.append(cv2.resize(frame, (frame_width, frame_height)))\n",
    "                    if(len(frames) % 1000 == 0):\n",
    "                        print(\"Frame Count = \", len(frames))\n",
    "                else:\n",
    "                    break\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    video.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oYIdfp_zseNl"
   },
   "source": [
    "### Define function to covert a frame sequence list to dataset\n",
    "The following function converts a given list of window triples to an X-Y dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y_jgmfAsio1A"
   },
   "outputs": [],
   "source": [
    "def window_triple_to_dataset(frame_sequences):\n",
    "    num_sequences = len(frame_sequences)\n",
    "    X = np.zeros((num_sequences, window_dim, window_dim, 6), dtype=np.uint8)\n",
    "    Y = np.zeros((num_sequences, window_dim, window_dim, 3), dtype=np.uint8)\n",
    "    for i, sequence in enumerate(frame_sequences):\n",
    "        X[i, :, :, 0:3] = frame_sequences[i][0]\n",
    "        Y[i, :, :, 0:3] = frame_sequences[i][1]\n",
    "        X[i, :, :, 3:6] = frame_sequences[i][2]\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QLsbmUkasyjx"
   },
   "source": [
    "### Get useful dataset\n",
    "The following piece of code creates a dataset of window triples and saves it to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5p-0aWb3Ky7d"
   },
   "outputs": [],
   "source": [
    "final_window_triple_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "20KZTSh5NPIK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cropped sequence count = 3000\n",
      "Useful sequence count = 101\n"
     ]
    }
   ],
   "source": [
    "frame_list = get_frames(videos_directory + 'clip1.mp4', 0, 15000)\n",
    "window_triples = get_window_triples(frame_list, 100000, 30, 0.14, 0.62, 0.24)\n",
    "useful_window_triples = extract_useful_window_triples(cropped_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W2vBok6zSIG3"
   },
   "outputs": [],
   "source": [
    "final_window_triple_list.extend(useful_window_triples[0:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lyq1-PjkxX5Y"
   },
   "outputs": [],
   "source": [
    "final_window_triple_list = sorted(final_window_triple_list, key=average_window_evaluator, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BK6OdFzMrhSP"
   },
   "outputs": [],
   "source": [
    "X, Y = window_triple_to_dataset(final_window_triple_list)\n",
    "np.save(dataset_directory + 'X_dummy.npy', X)\n",
    "np.save(dataset_directory + 'Y_dummy.npy', Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZNXWlGvcpnRq"
   },
   "outputs": [],
   "source": [
    "''' Periodically deleteing unnecessary variables to keep memory usage low '''\n",
    "del frame_list\n",
    "del cropped_sequences\n",
    "del useful_cropped_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KII6ROfTS472"
   },
   "outputs": [],
   "source": [
    "len(final_frame_sequence_list)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Dataset.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
