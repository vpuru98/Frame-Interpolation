{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fmyrdKwH1Vur"
   },
   "source": [
    "### Import Libraries\n",
    "Keras, Tensorflow, Numpy and sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "vqvC2Dl5tQF4",
    "outputId": "f5078d76-efbe-4063-abdf-4aa09aff2bb8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.metrics import MeanSquaredError\n",
    "from keras.utils.layer_utils import count_params\n",
    "from keras.layers import Activation, Conv2D, Input, Add\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [2.5, 2.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UoUpyMph1auD"
   },
   "source": [
    "### Define Constants\n",
    "Here I am defining some constants which we will be used throughout the notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NGeN_7UTto6-"
   },
   "outputs": [],
   "source": [
    "''' The dimesnion of the window for which we want to make predictions '''\n",
    "WINDOW_DIM = 80\n",
    "\n",
    "''' The dimension of the to be window predicted by the model '''\n",
    "MODEL_OUTPUT_DIM = 76\n",
    "\n",
    "''' The offset for the prediction window within the input window '''\n",
    "MODEL_WINDOW_START = (WINDOW_DIM - MODEL_OUTPUT_DIM) // 2\n",
    "\n",
    "''' Definition of important directories '''\n",
    "root_directory = '../'\n",
    "dataset_directory = root_directory + 'Dataset/'\n",
    "model_directory = root_directory + 'Model/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AOkq3LZ01xzM"
   },
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DVXFkE5ruQtr"
   },
   "outputs": [],
   "source": [
    "X_dataset = np.array(np.load(dataset_directory + 'X_dummy.npy'), dtype=np.uint8)\n",
    "Y_dataset = np.array(np.load(dataset_directory + 'Y_dummy.npy'), dtype=np.uint8)\n",
    "dataset_length = X_dataset.shape[0]\n",
    "\n",
    "X = np.zeros((dataset_length, WINDOW_DIM, WINDOW_DIM, 6), dtype=np.uint8) \n",
    "Y = np.zeros((dataset_length, MODEL_OUTPUT_DIM, MODEL_OUTPUT_DIM, 3), dtype=np.uint8)\n",
    "for i in range(0, dataset_length): \n",
    "    X[i - 0, :, :, :] = X_dataset[i, 0:WINDOW_DIM, 0:WINDOW_DIM, :]\n",
    "    Y[i - 0, :, :, :] = Y_dataset[i, MODEL_WINDOW_START:MODEL_WINDOW_START + MODEL_OUTPUT_DIM, \n",
    "            MODEL_WINDOW_START:MODEL_WINDOW_START + MODEL_OUTPUT_DIM, 0:3]\n",
    "\n",
    "# \n",
    "del X_dataset, Y_dataset\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.05, random_state=0)\n",
    "del X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W_ZzL0xy69qP"
   },
   "source": [
    "### Measure dataset roughness statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j3NUb61Ar96J"
   },
   "source": [
    "Here, I am trying to use the degree of deviation of the middle frame generated via averaging, from the actual middle frame, to model the difficulty of prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7vomHMMZ7K22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averaging Train MSE = 157.86339663216214\n",
      "Averaging Test MSE = 170.77380540166206\n"
     ]
    }
   ],
   "source": [
    "''' Train MSE by averaging '''\n",
    "print(\"Averaging Train MSE = {}\".format(np.mean((((X_train[:, MODEL_WINDOW_START:MODEL_WINDOW_START + MODEL_OUTPUT_DIM, \n",
    "        MODEL_WINDOW_START:MODEL_WINDOW_START + MODEL_OUTPUT_DIM, 0:3].astype(np.uint16) + X_train[:, MODEL_WINDOW_START:MODEL_WINDOW_START + \n",
    "        MODEL_OUTPUT_DIM, MODEL_WINDOW_START:MODEL_WINDOW_START + MODEL_OUTPUT_DIM, 3:6].astype(np.uint16)) // 2) - Y_train) ** 2)))\n",
    "\n",
    "''' Test MSE by averaging '''\n",
    "print(\"Averaging Test MSE = {}\".format(np.mean((((X_test[:, MODEL_WINDOW_START:MODEL_WINDOW_START + MODEL_OUTPUT_DIM, \n",
    "        MODEL_WINDOW_START:MODEL_WINDOW_START + MODEL_OUTPUT_DIM, 0:3].astype(np.uint16) + X_test[:, MODEL_WINDOW_START:MODEL_WINDOW_START + \n",
    "        MODEL_OUTPUT_DIM, MODEL_WINDOW_START:MODEL_WINDOW_START + MODEL_OUTPUT_DIM, 3:6].astype(np.uint16)) // 2) - Y_test) ** 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z_IWYten1hrC"
   },
   "source": [
    "### Define the cost funtion for our model\n",
    "\n",
    "Our cost function is going to consist of two parts. The first part simply computes the mean squared error between the actual middle frame and the predicted middle frame. The second part of our cost function tries to capture how well defined are the edges of different objects within the predicted frame, and penalizes the model for blurry and noisy images.\n",
    "\n",
    "The second part of the cost function defined above may seem slightly redundant, as the mean squared error function is also capable of penalizing the model for producing blurry images. However, adding another cost part, which caters specially to the degree of definition of edges within the output frame, does not hurt, especially when we consider the fact that number of points lying on the edges of an object are much less, when compared to number of points lying within an object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CJP_-I7WqXuK"
   },
   "outputs": [],
   "source": [
    "''' The relative weight of the second part of our cost function '''\n",
    "EDGE_LOSS_WEIGHT = 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' A differentiale version of tf.math.greater '''\n",
    "def greater(input_tensor, val):\n",
    "    input_tensor_diff = tf.math.subtract(input_tensor, tf.constant(val))\n",
    "    return tf.math.divide_no_nan(input_tensor_diff, tf.nn.relu(input_tensor_diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ri_4-YiytstB"
   },
   "outputs": [],
   "source": [
    "''' The function defined below models the degree of definition of edges within \n",
    "    the output frame, by computing the dissimilarity ofany pixel from its neighboring pixels.\n",
    "'''\n",
    "def compute_edge_loss(y_pred, y_true, max_translation):\n",
    "    dim = MODEL_OUTPUT_DIM\n",
    "    pred_diff, true_diff = tf.constant(0.0), tf.constant(0.0)\n",
    "    for i in range(-max_translation, max_translation + 1):\n",
    "        for j in range(-max_translation, max_translation + 1):\n",
    "            y_pred_window_1 = tf.slice(y_pred, [0, max(0, i), max(0, j), 0], [-1, min(dim, dim + i) - \n",
    "                    max(0, i), min(dim, dim + j) - max(0, j), -1])\n",
    "            y_pred_window_2 = tf.slice(y_pred, [0, max(0, -i), max(0, -j), 0], [-1, min(dim, dim - i) - \n",
    "                    max(0, -i), min(dim, dim - j) - max(0, -j), -1])\n",
    "            y_true_window_1 = tf.slice(y_true, [0, max(0, i), max(0, j), 0], [-1, min(dim, dim + i) - \n",
    "                    max(0, i), min(dim, dim + j) - max(0, j), -1])\n",
    "            y_true_window_2 = tf.slice(y_true, [0, max(0, -i), max(0, -j), 0], [-1, min(dim, dim - i) - \n",
    "                    max(0, -i), min(dim, dim - j) - max(0, -j), -1])\n",
    "            \n",
    "            y_pred_diff = (tf.cast(greater(tf.math.reduce_sum(tf.math.abs(tf.math.subtract(y_pred_window_1, \n",
    "                    y_pred_window_2)), axis=3), 60.0), dtype=tf.float32) * 50)\n",
    "            y_true_diff = (tf.cast(greater(tf.math.reduce_sum(tf.math.abs(tf.math.subtract(y_true_window_1, \n",
    "                    y_true_window_2)), axis=3), 60.0), dtype=tf.float32) * 50)\n",
    "            pred_diff = tf.math.add(pred_diff, tf.slice(y_pred_diff, [0, max_translation - max(0, i), max_translation - max(0, j)], \n",
    "                    [-1, dim - 2 * max_translation, dim - 2 * max_translation]))\n",
    "            true_diff = tf.math.add(true_diff, tf.slice(y_true_diff, [0, max_translation - max(0, i), max_translation - max(0, j)], \n",
    "                    [-1, dim - 2 * max_translation, dim - 2 * max_translation]))\n",
    "            \n",
    "    return tf.math.squared_difference(tf.math.reduce_mean(pred_diff, axis=[1, 2]), tf.math.reduce_mean(true_diff, axis=[1, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FVutewuKqbN_"
   },
   "outputs": [],
   "source": [
    "''' The overall cost function '''\n",
    "def edge_fill_loss(y_pred, y_true):\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    loss = tf.math.reduce_mean(tf.math.squared_difference(y_pred, y_true), axis=[1, 2, 3])\n",
    "    loss = tf.math.add(loss, tf.constant(EDGE_LOSS_WEIGHT) * compute_edge_loss(y_pred, y_true, 1))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K7KbWmHKsWzM"
   },
   "source": [
    "### Define function to retreive a keras model\n",
    "I am using a 13 layer deep convolutional network for our task. You would notice that I haven't used any downsampling layers, so as to preserve imformation for frame regeneration. Also, I tried using resnets, but that did not seem to provide any appreciable improvements over the current model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uFUm5sEEqjDe"
   },
   "outputs": [],
   "source": [
    "def get_model(reg_const=0):\n",
    "    inputs = Input(shape=(WINDOW_DIM, WINDOW_DIM, 6))\n",
    "    Y = Activation('relu')(Conv2D(200, kernel_size=3, padding='valid', strides=(1, 1), kernel_regularizer=l2(reg_const))(inputs))\n",
    "    Y = Activation('relu')(Conv2D(200, kernel_size=3, padding='valid', strides=(1, 1), kernel_regularizer=l2(reg_const))(Y))\n",
    "    Y = Activation('relu')(Conv2D(200, kernel_size=3, padding='same', strides=(1, 1), kernel_regularizer=l2(reg_const))(Y))\n",
    "    Y = Activation('relu')(Conv2D(250, kernel_size=3, padding='same', strides=(1, 1), kernel_regularizer=l2(reg_const))(Y))\n",
    "    Y = Activation('relu')(Conv2D(250, kernel_size=3, padding='same', strides=(1, 1), kernel_regularizer=l2(reg_const))(Y))\n",
    "    Y = Activation('relu')(Conv2D(250, kernel_size=3, padding='same', strides=(1, 1), kernel_regularizer=l2(reg_const))(Y))\n",
    "    Y = Activation('relu')(Conv2D(300, kernel_size=3, padding='same', strides=(1, 1), kernel_regularizer=l2(reg_const))(Y))\n",
    "    Y = Activation('relu')(Conv2D(300, kernel_size=3, padding='same', strides=(1, 1), kernel_regularizer=l2(reg_const))(Y))\n",
    "    Y = Activation('relu')(Conv2D(300, kernel_size=3, padding='same', strides=(1, 1), kernel_regularizer=l2(reg_const))(Y))\n",
    "    Y = Activation('relu')(Conv2D(350, kernel_size=3, padding='same', strides=(1, 1), kernel_regularizer=l2(reg_const))(Y))\n",
    "    Y = Activation('relu')(Conv2D(350, kernel_size=3, padding='same', strides=(1, 1), kernel_regularizer=l2(reg_const))(Y))\n",
    "    Y = Activation('relu')(Conv2D(350, kernel_size=3, padding='same', strides=(1, 1))(Y))\n",
    "    Y = Activation('relu')(Conv2D(3, kernel_size=7, padding='same', strides=(1, 1))(Y))\n",
    "    model = Model(inputs=inputs, outputs=Y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UUm1ejgp6eI9"
   },
   "source": [
    "### Train Model\n",
    "The following section of code retreives a kears model instance and trains it over a number of epochs. Also I'm using mean squared error as our model evaluation metric throughout the rest of the notebook, instead of the entire two part cost function we defined above. (The use of different functions for training and evaluation may seem incorrect, but since the mean squared error function is essentially the meat and bones of our cost function, I figured no harm could be incurred if we did use MSE for evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "93oNbVGOqmJ4",
    "outputId": "11b5d1fe-d86d-4642-e1eb-d17b483c0494"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable Parameters Count =  7805553\n"
     ]
    }
   ],
   "source": [
    "''' Retreive a kears model instance '''\n",
    "model = get_model(0.0)\n",
    "print(\"Trainable Parameters Count = \", count_params(model.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "6BFDJbIUu4xC",
    "outputId": "310d83f1-1ac5-4c8a-dc17-e00a8b3205c3"
   },
   "outputs": [],
   "source": [
    "''' Define a model checkpoint to save the weights of the model to file after each epoch of training '''\n",
    "checkpoint_filepath = model_directory + 'model80_76_.h5'\n",
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath, \n",
    "    monitor='loss',\n",
    "    save_weights_only=True,\n",
    "    save_best_only=True, \n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss=edge_fill_loss,\n",
    "    optimizer=Adam(0.00004), \n",
    "    metrics=[MeanSquaredError()] \n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    x=X_train, \n",
    "    y=Y_train,  \n",
    "    epochs=12,\n",
    "    batch_size=64, \n",
    "    validation_data=(X_test, Y_test), \n",
    "    callbacks=[model_checkpoint_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f8BI0c1_6iAK"
   },
   "source": [
    "### Evaluate Model\n",
    "Obtain model MSE for the train and the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NkXhtBtJu78h"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Train MSE = 238.6639862060547\n",
      "Model Test MSE = 251.4951934814453\n"
     ]
    }
   ],
   "source": [
    "''' Train MSE '''\n",
    "Y_pred_train = model.predict(X_train)\n",
    "print(\"Model Train MSE = {}\".format(np.mean((Y_pred_train - Y_train) ** 2)))\n",
    "\n",
    "''' Test MSE '''\n",
    "Y_pred_test = model.predict(X_test)\n",
    "print(\"Model Test MSE = {}\".format(np.mean((Y_pred_test - Y_test) ** 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IF4Vgnxg6sBV"
   },
   "source": [
    "### Test Model\n",
    "The following piece of code obtains a middle frame prediction for a pair of frames, and compares the quality of prediction against the average frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O_zyYP7DqvVZ"
   },
   "outputs": [],
   "source": [
    "''' Index of the example to be chosen from the test set '''\n",
    "NUM = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ra43IThWvbU9"
   },
   "outputs": [],
   "source": [
    "X1 = (X_test[NUM, MODEL_WINDOW_START:MODEL_WINDOW_START + MODEL_OUTPUT_DIM, \n",
    "        MODEL_WINDOW_START:MODEL_WINDOW_START + MODEL_OUTPUT_DIM, 0:3])\n",
    "X2 = (X_test[NUM, MODEL_WINDOW_START:MODEL_WINDOW_START + MODEL_OUTPUT_DIM, \n",
    "        MODEL_WINDOW_START:MODEL_WINDOW_START + MODEL_OUTPUT_DIM, 3:6])\n",
    "\n",
    "Y_pred = model.predict(X_test[[NUM], 0:WINDOW_DIM, 0:WINDOW_DIM, :])[0] \n",
    "Y_pred = np.maximum(0, Y_pred)\n",
    "Y_pred = np.minimum(255, Y_pred)\n",
    "Y_act = (Y_test[NUM, :, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow((X1 / 255)[:, :, ::-1])\n",
    "print('\\nThe first frame\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow((X2 / 255)[:, :, ::-1])\n",
    "print('\\nThe second frame\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow((Y_pred.astype(np.uint8) / 255)[:, :, ::-1])\n",
    "print('\\nThe predicted middle frame\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow((Y_act / 255)[:, :, ::-1])\n",
    "print('\\nThe actual middle frame\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JUCPxAcssvju"
   },
   "source": [
    "The function defined below is essentially the numpy version of the second part of the cost function we defined above. It can be used to gain an insight into what the target edge definition for any middle frame looks like, and how well the model is able to achieve it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZpQg2od8391L"
   },
   "outputs": [],
   "source": [
    "def edge_detection(img, max_translation):\n",
    "    dim = img.shape[0]\n",
    "    result = np.zeros((dim - 2 * max_translation, dim - 2 * max_translation))\n",
    "    for i in range(-max_translation, max_translation + 1):\n",
    "        for j in range(-max_translation, max_translation + 1):\n",
    "            img_window_1 = np.array(img[max(0, i):min(dim, dim + i), max(0, j):min(dim, dim + j), :], dtype=np.float32)\n",
    "            img_window_2 = np.array(img[max(0, -i):min(dim, dim - i), max(0, -j):min(dim, dim - j), :], dtype=np.float32)\n",
    "            img_diff = np.array(np.sum(np.absolute(img_window_1 - img_window_2), axis=2) > 60) * 50\n",
    "            upp_index = max_translation - max(0, i)\n",
    "            down_index = upp_index + dim - 2 * max_translation\n",
    "            left_index = max_translation - max(0, j)\n",
    "            right_index = left_index + dim - 2 * max_translation\n",
    "            result[:, :] += img_diff[upp_index:down_index, left_index:right_index]\n",
    "    plt.imshow(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bq6edsKL4ACd"
   },
   "outputs": [],
   "source": [
    "edge_detection(Y_act, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_detection(Y_pred, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YcjG35hV6xlr"
   },
   "source": [
    "### Save model to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "leJ2rtiRvKEj"
   },
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(model_directory + 'model80_76.json', \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CRvV_fkY63Se"
   },
   "source": [
    "### Load model from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ll87hnLFq9pp"
   },
   "outputs": [],
   "source": [
    "json_file = open(model_directory + 'model80_76.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "\n",
    "from keras.models import model_from_json\n",
    "model = model_from_json(loaded_model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h8RJVgySvROj"
   },
   "outputs": [],
   "source": [
    "model.load_weights(model_directory + 'model80_76.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p5btjAANrFcB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 80, 80, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 78, 78, 200)       11000     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 78, 78, 200)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 76, 76, 200)       360200    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 76, 76, 200)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 76, 76, 200)       360200    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 76, 76, 200)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 76, 76, 250)       450250    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 76, 76, 250)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 76, 76, 250)       562750    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 76, 76, 250)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 76, 76, 250)       562750    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 76, 76, 250)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 76, 76, 300)       675300    \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 76, 76, 300)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 76, 76, 300)       810300    \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 76, 76, 300)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 76, 76, 300)       810300    \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 76, 76, 300)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 76, 76, 350)       945350    \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 76, 76, 350)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 76, 76, 350)       1102850   \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 76, 76, 350)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 76, 76, 350)       1102850   \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 76, 76, 350)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 76, 76, 3)         51453     \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 76, 76, 3)         0         \n",
      "=================================================================\n",
      "Total params: 7,805,553\n",
      "Trainable params: 7,805,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
